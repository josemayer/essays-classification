\chapter{Introdução}

Tradicionalmente, técnicas de classificação de texto têm desempenhado um papel fundamental na avaliação e atribuição de notas a redações com base em vários parâmetros, como conteúdo, estrutura, coerência e proficiência linguística. Algoritmos clássicos de aprendizado de máquina têm sido utilizados para identificar e avaliar características-chave dentro das redações, com o intuito de mimetizar o processo humano de correção manual dos textos. Essas técnicas muitas vezes dependem de padrões avaliados sob medida e de conhecimento específico do domínio, o que pode ser trabalhoso e menos adaptável à natureza dinâmica da linguagem.

Além disso, os modelos tradicionais de avaliação textual automática enfrentam desafios na compreensão da semântica e do contexto das redações. Por exemplo, podem ter dificuldade em reconhecer nuances, metáforas ou referências culturais, que são aspectos críticos de uma correção eficaz. Tal limitação abriu caminho para modelos mais sofisticados, capazes de capturar a essência da linguagem humana de maneira mais abrangente.

Em particular, o surgimento recente de modelos de linguagem como o \textit{Bidirectional Encoder Representations from Transformers} (BERT) e as arquiteturas de \textit{transformers} auxiliou na mitigação desse problema. O BERT, introduzido pelo Google em 2018, revolucionou a área de Processamento de Linguagem Natural (NLP) ao introduzir os \textit{embeddings}\footnote{\textit{Embeddings}, no âmbito do NLP, são representações vetoriais numéricas de palavras, cuja codificação tem o intuito de garantir que o computador entenda seu contexto e semântica.} contextualizados de palavras. Os \textit{transformers}, arquitetura subjacente ao BERT, se destacaram, por sua vez, em várias tarefas de NLP ao considerar o contexto e as relações entre palavras, tornando-os excepcionalmente adequados para a avaliação de redações.

Esses modelos operam com base nos princípios de pré-treinamento e de ajuste fino. Durante a fase do pré-treinamento, aprendem as complexidades da linguagem ao prever palavras ausentes em frases e compreender o contexto em que são usadas. Posteriormente, o ajuste fino permite que os modelos se adaptem a tarefas específicas, como a correção automática, a partir do treinamento com dados já rotulados. A capacidade de considerar a redação como uma unidade contextual, em oposição a palavras ou frases isoladas, capacita os \textit{transformers} a capturar as complexidades da linguagem, incluindo semântica, coerência e até mesmo significados subjacentes ao texto, características importantes para os critérios de avaliação do Exame Nacional do Ensino Médio (ENEM).

Utilizando-se do BERT e dos modelos de linguagem baseados na arquitetura de \textit{transformers}, os sistemas de avaliação automática de redações testemunharam um avanço significativo em sua capacidade de imitar os avaliadores humanos. Esses modelos podem avaliar a qualidade completa do texto, reconhecer nuances da língua portuguesa e fornecer uma nota coerente de acordo com as competências exigidas no exame. Ao longo desta monografia, exploraremos os princípios do ajuste fino do BERT na correção automática de redações com enfoque no modelo do ENEM, os desafios abarcados por essa tarefa e, por fim, o potencial dessa abordagem em relação aos métodos tradicionais e humanos de avaliação.
